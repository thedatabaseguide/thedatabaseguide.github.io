{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Welcome to MkDocs","text":""},{"location":"#welcome-to-mkdocs","title":"Welcome to MkDocs","text":"<p>icons8</p> <p>Favicon Converter</p>"},{"location":"baas/overview/","title":"Overview","text":""},{"location":"baas/overview/#overview","title":"Overview","text":"<p>Backend-as-a-Service (BaaS) is a cloud service model in which developers outsource all the behind-the-scenes aspects of a web or mobile application so that they only have to write and maintain the frontend.</p> <p>BaaS vendors provide pre-written software for activities that take place on servers, such as user authentication, database management, remote updating, and push notifications (for mobile apps), as well as cloud storage and hosting.</p> What is Backend as a Service (BaaS)? <p>Backend as a Service (BaaS) is a cloud service model that provides developers with a way to connect their web and mobile applications to cloud-based servers via APIs and SDKs. BaaS platforms offer a suite of features that typically include database management, user authentication, cloud storage, push notifications, server-side logic, and more, without the need for developers to manage or maintain the underlying server infrastructure.</p> <p>BaaS is like that magical box for app developers. It gives them pre-built pieces of the castle's interior (or, in app terms, pre-built backend services). This means developers can just pick what they need (like user login or data storage), and it's ready to use in their app. They don't have to build these services from scratch. It's faster and lets them focus on making the app look good and work well \u2014 just like focusing on building the exterior of your LEGO castle.</p> <p>Backend as a service (BaaS) is a third-party service that lets you develop an app or a website without bothering with its backend.</p> <p>When using BaaS, you leave time-consuming and expensive backend tasks to a BaaS provider while channeling your efforts into the front-end.</p> <p></p> <p> </p>"},{"location":"baas/overview/#what-is-included-in-baas","title":"What is included in BaaS?","text":"<p>BaaS providers offer a number of server-side capabilities. For instance:</p> <ul> <li>Database management</li> <li>Cloud storage (for user-generated content)</li> <li>User authentication</li> <li>Push notifications</li> <li>Remote updating</li> <li>Hosting</li> <li>Other platform- or vendor-specific functionalities; for instance, Firebase offers Google search indexing</li> </ul> <p>BaaS and MBaaS providers include Google Firebase and Microsoft Azure.</p>"},{"location":"baas/overview/#reference","title":"Reference","text":"<ul> <li>What is BaaS? | Backend-as-a-Service vs. serverless</li> <li>Why would you use Backend as a Service (BaaS)?</li> <li>Backend as a Service (BaaS)</li> <li>First Look at Baas</li> </ul>"},{"location":"blog/","title":"Index","text":""},{"location":"blog/#blog","title":"Blog","text":""},{"location":"blog/2024/04/29/my-first-blog/","title":"My First Blog","text":""},{"location":"blog/2024/04/29/my-first-blog/#my-first-blog","title":"My First Blog","text":"<p>lorem ipsum</p>"},{"location":"books/docker-compose/","title":"Docker Compose","text":""},{"location":"books/docker-compose/#django-with-mysql","title":"<code>Django</code> with <code>MySql</code>","text":"<p>If you choose <code>Docker Compose</code> to deploy your Django web application along with a MySQL database, you would typically follow these steps:</p> <ul> <li><code>Dockerfile</code> for Django App:</li> </ul> <p>Here's a basic example of what a Dockerfile for a Django application might look like:</p> <pre><code>FROM python:3.9\n\nWORKDIR /app\n\nCOPY requirements.txt /app/\nRUN pip install --no-cache-dir -r requirements.txt\n\nCOPY . /app/\n\nCMD [\"python\", \"manage.py\", \"runserver\", \"0.0.0.0:8000\"]\n</code></pre> <ul> <li><code>docker-compose.yml</code>:</li> </ul> <p>Below is an example <code>docker-compose.yml</code> file for a Django app with a MySQL database:</p> <pre><code>  version: '3'\n\n  services:\n  db:\n      image: mysql:5.7\n      restart: always\n      environment:\n      MYSQL_DATABASE: 'mydatabase'\n      MYSQL_USER: 'myuser'\n      MYSQL_PASSWORD: 'mypassword'\n      MYSQL_ROOT_PASSWORD: 'rootpassword'\n      ports:\n      - '3306:3306'\n\n  web:\n      build: .\n      command: python manage.py runserver 0.0.0.0:8000\n      volumes:\n      - .:/app\n      ports:\n      - '8000:8000'\n      depends_on:\n      - db\n</code></pre> <ul> <li>Django <code>Settings</code>:</li> </ul> <p>Make sure your Django application's settings are configured to use the MySQL database. You'll need to update the <code>DATABASES</code> setting in your Django <code>settings.py</code> file to point to the MySQL database container</p> <ul> <li>Run <code>Docker Compose</code>:</li> </ul> <p>Run docker-compose up in the directory containing your docker-compose.yml file. This command will start the containers defined in the docker-compose.yml file. Docker Compose will build the Docker images (if necessary) and start the containers for your Django app and MySQL database.</p> <ul> <li><code>Access</code> Your Application:</li> </ul> <p>Once Docker Compose has started the containers, you should be able to access your Django application by navigating to <code>http://localhost:8000</code> in your web browser.</p>"},{"location":"books/jenkins-guide/","title":"Jenkins Guide","text":"<p>jenkins</p> <ol> <li> <p>Adding Restart Policies:</p> <p>You might want to add a restart policy to ensure that the Jenkins container automatically restarts if it crashes or if Docker restarts. This can be done using the <code>--restart</code> flag. For example, you could use <code>--restart</code> unless-stopped to ensure the container restarts unless explicitly stopped.</p> </li> <li> <p>Volume Mounts for Persistence:</p> <p>Jenkins typically stores its data in <code>/var/jenkins_home</code> directory within the container. If you want to persist Jenkins data between container restarts or updates, you can mount a volume from the host machine to this directory. This can be achieved using the <code>-v</code> flag. For example, <code>-v</code> <code>jenkins_home:/var/jenkins_home</code> would mount a volume named <code>jenkins_home</code> to the Jenkins home directory.</p> </li> </ol> bash<pre><code>docker run -d \\\n  -p 8080:8080 \\\n  -p 50000:50000 \\\n  --name jenkins \\\n  --restart unless-stopped \\\n  -v jenkins_home:/var/jenkins_home \\\n  -v /var/run/docker.sock:/var/run/docker.sock \\\n  jenkins/jenkins:lts\n</code></pre> <p>This command ensures that the Jenkins container runs in detached mode, exposes ports <code>8080</code> and <code>50000</code>, has a restart policy set to \"unless stopped,\" mounts a volume named <code>jenkins_home</code> for data persistence, and uses the LTS version of the Jenkins image.</p> <p>Notes:</p> <p>The <code>-v</code> flag in Docker is used to specify volume mounts. It allows you to create a persistent data volume outside the container and mount it into the container at a specified path.</p> <p>For example, <code>-v</code> <code>/host/directory:/container/directory</code> would mount the directory <code>/host/</code>directory on the host machine into the directory <code>/container/directory</code> within the container.</p> <p>In the context of running Jenkins, you typically want to persist Jenkins data, such as configuration, plugins, and job data, across container restarts. This is achieved by mounting a volume to the <code>/var/jenkins_home</code> directory within the Jenkins container.</p> <p>So, when you use <code>-v</code> <code>jenkins_home:/var/jenkins_home</code>, Docker will create a volume named jenkins_home and mount it into the <code>/var/jenkins_home</code> directory in the container. This ensures that Jenkins data is stored outside the container and persists even if the container is removed or recreated.</p> <p>In summary, when you see <code>-v</code> in a Docker command, it's indicating a volume mount, allowing you to persist data outside the container.</p>"},{"location":"books/jenkins-guide/#docker-with-docker-in-docker-dind","title":"Docker with Docker-in-Docker (DinD):","text":"<p>If you're running Jenkins within a Docker container, you can use Docker-in-Docker (DinD) to allow Jenkins to run Docker commands inside its own Docker containers. However, this approach has security implications and might not be recommended for production use without proper precautions.</p> bash<pre><code>docker run -d \\\n  -p 8080:8080 \\\n  -p 50000:50000 \\\n  --name jenkins \\\n  --restart unless-stopped \\\n  -v jenkins_home:/var/jenkins_home \\\n  -v /var/run/docker.sock:/var/run/docker.sock \\\n  jenkins/jenkins:lts\n</code></pre> <p>If you want to include Docker-in-Docker (DinD) functionality in your Jenkins container setup, you'll need to bind the Docker socket (/var/run/docker.sock) from the host machine to the Jenkins container. This allows the Jenkins container to communicate with the Docker daemon running on the host machine.</p> <p>Here's the modified command to include the Docker socket binding:</p> bash<pre><code>docker run -d \\\n  -p 8080:8080 \\\n  -p 50000:50000 \\\n  --name jenkins \\\n  --restart unless-stopped \\\n  -v jenkins_home:/var/jenkins_home \\\n  -v /var/run/docker.sock:/var/run/docker.sock \\\n  jenkins/jenkins:lts\n</code></pre> <p>I've added <code>-v</code> <code>/var/run/docker.sock:/var/run/docker.sock</code> to the command, which binds the Docker socket from the host to the Jenkins container. This allows Jenkins to execute Docker commands inside the container.</p> <p>Now, with this setup, your Jenkins container will have access to Docker commands, allowing you to run Docker builds, start containers, and manage images as part of your Jenkins jobs or pipeline. Make sure to consider the security implications of allowing Jenkins to access the Docker daemon in this way.</p> <p> Solving </p> <p>If you want to pull Docker images within your Jenkins Dockerfile without adding the Docker installation steps, you can indeed simplify your Dockerfile. Here's how you can modify it to only pull Docker images:</p> bash<pre><code>FROM jenkins/jenkins:lts\n\nUSER root\n\n# Add Jenkins user to Docker group\nRUN usermod -aG docker jenkins\n\nUSER jenkins\n</code></pre> <p>With this Dockerfile, you're starting from the official Jenkins LTS image, switching to the root user to add the Jenkins user to the Docker group, and then switching back to the Jenkins user. This will allow Jenkins to pull Docker images without needing to install Docker within the Jenkins container itself.</p> <p>Remember that for this to work, you'll still need to mount the Docker socket from the host machine into the Jenkins container when you run the container. This will allow Jenkins to communicate with the Docker daemon running on the host and pull Docker images. Here's an example of how you can run the container with the Docker socket mounted:</p> bash<pre><code>docker run -d \\\n  -v /var/run/docker.sock:/var/run/docker.sock \\\n  -p 8080:8080 \\\n  -p 50000:50000 \\\n  --name jenkins \\\n  your_custom_jenkins_image\n</code></pre> <p>Replace <code>your_custom_jenkins_image</code> with the name of your custom Jenkins image built from the Dockerfile. With this setup, your Jenkins container will be able to pull Docker images using the Docker CLI on the host machine.</p>"},{"location":"books/jenkins-guide/#docker-images-types","title":"Docker Images Types","text":"<p>In Docker, an <code>image</code> is a lightweight, standalone, and executable package that includes everything needed to run a piece of software, including the code, a runtime, libraries, environment variables, and configuration files. When you run a Docker image, it creates a container, which is an instance of that image.</p> <p>Whether an image \"runs\" or not depends on what it's designed to do:</p> <ol> <li> <p>Runnable Images:</p> <p>These are images designed to start a process or service that runs continuously or performs some action until explicitly stopped. Examples include web servers, databases, or any other application that provides a service and needs to keep running.</p> </li> <li> <p>One-shot Images:</p> <p>Some images are designed to perform a specific task or action and then exit. These images are typically used for utilities, scripts, or diagnostic tools. They execute their task and then terminate. The <code>hello-world</code> image is an example of this. Other examples might include images for performing backups, data migrations, or other batch operations.</p> </li> </ol> <p>So, all images can be run, but the behavior of what they do when they're run can differ. Some images are meant to continuously run services, while others perform a task and then exit.</p> <p>Notes:</p> <p>Containers need a runnable image to exist. </p>"},{"location":"books/jenkins-guide/#types-of-containers-in-docker","title":"Types of Containers in Docker","text":"<ul> <li>Stateless Containers</li> <li>Stateful Containers</li> <li>Ephemeral Containers</li> </ul>"},{"location":"books/jenkins-guide/#dockerfile-application","title":"Dockerfile application","text":"<p>To create a simple HTML file with \"Hello, World!\" content and then build a Docker image containing this HTML file, you can follow these steps:</p> <ol> <li> <p>Create a simple HTML file named index.html with the \"Hello, World!\" content:</p> html<pre><code>&lt;!-- index.html --&gt;\n&lt;!DOCTYPE html&gt;\n&lt;html lang=\"en\"&gt;\n&lt;head&gt;\n    &lt;meta charset=\"UTF-8\"&gt;\n    &lt;meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\"&gt;\n    &lt;title&gt;Hello, World!&lt;/title&gt;\n&lt;/head&gt;\n&lt;body&gt;\n    &lt;h1&gt;Hello, World!&lt;/h1&gt;\n&lt;/body&gt;\n&lt;/html&gt;\n</code></pre> </li> <li> <p>Create a <code>Dockerfile</code> in the same directory to build the Docker image:</p> <pre><code># Dockerfile\nFROM nginx:alpine\nCOPY index.html /usr/share/nginx/html/index.html\n</code></pre> </li> <li> <p>Now, build the Docker image using the docker build command:</p> bash<pre><code>docker build -t hello-world-html .\n</code></pre> <p>This command builds a Docker image named <code>hello-world-html</code> using the Dockerfile in the current directory (<code>.</code>).</p> </li> <li> <p>Once the image is built, you can run a container from it:</p> bash<pre><code>docker run -d -p 8080:80 --name hello-world-container hello-world-html\n</code></pre> <p>This command runs a container from the <code>hello-world-html</code> image, maps port <code>8080</code> on the host to port 80 in the container (<code>-p 8080:80</code>), and gives the container a name (<code>--name hello-world-container</code>).</p> <p>Now, you can visit <code>http://localhost:8080</code> in your web browser to see the \"<code>Hello, World!</code>\" message served by the Docker container running the HTML file.</p> </li> </ol> <p>That's it! You've created a simple HTML file, built a Docker image containing it, and run a Docker container serving the HTML content.</p>"},{"location":"books/jenkins-guide/#pushing-images-to-dockerhub","title":"Pushing <code>images</code> to <code>Dockerhub</code>","text":"<p>To push your Docker image to Docker Hub (which is commonly referred to as Docker's public registry), you need to follow these steps:</p> <ul> <li> <p>Tag your image:</p> <p>Before pushing your image, you need to tag it with your Docker Hub username and the repository name. The format is <code>username/repository:tag</code>. If you haven't tagged your image yet, you can do it using the following command:</p> bash<pre><code>docker tag hello-world-html yourusername/hello-world-html:latest\n</code></pre> <p>Replace <code>hello-world-html</code> with the name of your local image, and <code>yourusername</code> with your Docker Hub username. You can choose any tag you want; <code>latest</code> is commonly used.</p> </li> <li> <p>Log in to Docker Hub:</p> <p>Use the docker login command to log in to your Docker Hub account.</p> bash<pre><code>docker login\n</code></pre> <p>Enter your Docker Hub username and password when prompted.</p> </li> <li> <p>Push your image:</p> <p>After logging in, you can push your image to Docker Hub using the docker push command:</p> bash<pre><code>docker push yourusername/hello-world-html:latest\n</code></pre> <p>Replace <code>yourusername/hello-world-html:latest</code> with the full name of your image, including the tag you used.</p> </li> <li> <p>Verify:</p> <p>Once the push is complete, you can go to your Docker Hub account in your web browser to verify that the image has been successfully pushed.</p> </li> </ul> <p>Your image is now available on Docker Hub and can be pulled by anyone with access to it. Remember that if you plan to share your image publicly, make sure not to include any sensitive information or credentials within the image.</p>"},{"location":"books/jenkins-guide/#reference","title":"Reference","text":"<ul> <li> <p>What is a Docker image?</p> </li> <li> <p>Different Types of Docker Containers</p> </li> <li> <p>Docker images</p> </li> </ul>"},{"location":"books/pocket-devops/","title":"Pocker Devops","text":""},{"location":"books/pocket-devops/#devops","title":"Devops","text":""},{"location":"books/pocket-devops/#running-hello-world-in-docker","title":"Running Hello World in Docker","text":"<p>Problem</p> <p>You have access to a Docker host and want to run your first container. You want to learn the various life cycles of a container. As an example, you want to run a container and echo Hello World in it.</p> <p>Solution</p> <p>Typing docker at the prompt returns the usage of the docker command:</p> <p><code>$ docker</code></p> <p>Usage: <code>docker [OPTIONS] COMMAND [arg...]</code></p> <p>A self-sufficient runtime for linux containers.</p> <pre><code>Unable to find image 'busybox' locally\nbusybox:latest: The image you are pulling has been verified\n511136ea3c5a: Pull complete\ndf7546f9f060: Pull complete\ne433a6c5b276: Pull complete\ne72ac664f4f0: Pull complete\nStatus: Downloaded newer image for busybox:latest\nhello world\n</code></pre> <p>Containers are based on images. An image needs to be passed to the <code>docker run</code> command. In the preceding example, you specify an image called busybox. Docker does not have this image locally and pulls it from a public registry. A registry is a catalog of Docker images that the Docker client can communicate with and download images from. Once the image is pulled, Docker starts a container and executes the echo hello world command. Congratulations\u2014you ran your first container.</p>"},{"location":"books/pocket-devops/#knowing-the-difference-between-containers-and-virtual-machines","title":"Knowing the Difference Between Containers and Virtual Machines","text":"<p>In comparison, with <code>containers</code>, the sharing of the host OS\u2019s kernel with the application means that the overhead of an additional OS is removed.</p>"},{"location":"books/pocket-devops/#dockerfile","title":"Dockerfile","text":"<p>A Dockerfile is a set of instructions that tells Docker how to build an image. A typical Dockerfile is made up of the following:</p> <ul> <li>A <code>FROM</code> instruction that tells Docker what the base image is</li> <li>An <code>ENV</code> instruction to pass an environment variable.</li> <li>A <code>RUN</code> instruction to run some shell commands (for example, install-dependent programs not available in the base image).</li> <li>A <code>CMD</code> or an <code>ENTRYPOINT</code> instruction that tells Docker which executable to run when a container is started.</li> </ul>"},{"location":"books/pocket-devops/#docker-image","title":"Docker Image","text":"<p><code>Docker image</code> is a read-only template that forms the foundation of your application Docker images are created using a <code>series of commands</code>, known as instructions, in the <code>Dockerfile</code>. </p> <p>Breakdown of a <code>.Dockerfile</code></p> <ul> <li>A Docker image starts with a base image, such as Ubuntu.</li> <li>On top of this image, we can add build our application stack adding the packages as and when required.</li> </ul> <p>Notes:</p> <p>On the advanced scale, to keep the image size as low as possible, we can also start with slim packages, such as <code>Alpine</code> or even Scratch, which is Docker\u2019s reserved, minimal starting image for building other images.</p> <p>Every Docker image has an <code>associated tag</code>. Tags typically include <code>names</code> and <code>version labels</code>. While it is not mandatory to associate a version tag with a Docker image name, these tags make it easier to roll back to previous versions. Without a tag name, Docker must fetch the image with the latest tag. You can also provide a tag name to force-fetch a tagged image.</p>"},{"location":"books/pocket-devops/#docker-container","title":"Docker Container","text":"<p>A Docker image, when it\u2019s run in a host computer, spawns a process with its own namespace, known as a Docker container.</p> <p>The <code>main difference between</code> a Docker <code>image</code> and a <code>container</code> is the presence of a thin read/write layer known as the container layer. Any changes to the filesystem of a container, such as writing new files or modifying existing files, are done to this writable container layer than the lower layers.</p> <p>An important aspect to grasp is that when a container is running, the changes are applied to the container layer and when the container is stopped/killed, the container layer is not saved. Hence, all changes are lost. </p> <p>This aspect of containers is not understood very well and for this reason, stateful applications and those requiring persistent data were initially not recommended as containerized applications. However, with <code>Docker Volumes</code>, there are ways to get around this limitation.</p>"},{"location":"books/pocket-devops/#bind-mounts-and-volumes","title":"Bind Mounts and Volumes","text":"<p>Docker provides different ways to mount data into a container from the Docker host: </p> <ul> <li>volumes,</li> <li>bind mounts, &amp; </li> <li>tmpfs volumes.</li> </ul> <p>While <code>tmpfs volumes</code> are stored in the host system\u2019s memory only, <code>bind mounts</code> and <code>volumes</code> are stored in the host filesystem</p>"},{"location":"books/pocket-devops/#docker-engine","title":"Docker Engine","text":"<p>Docker Engine is the core part of Docker. Docker Engine is a client-server application that provides the platform, the runtime, and the tooling for building and managing Docker images, Docker containers, and more. Docker Engine provides the following:</p> <ul> <li>Docker daemon</li> <li>Docker CLI</li> <li>Docker API</li> </ul>"},{"location":"books/pocket-devops/#docker-daemon","title":"Docker Daemon","text":"<p>The Docker daemon is a <code>service</code> that runs in the background of the host computer and handles the heavy lifting of most of the Docker commands. The daemon listens for API requests for creating and managing Docker objects, such as <code>containers</code>, <code>networks</code>, and <code>volumes</code>.</p>"},{"location":"books/pocket-devops/#docker-cli","title":"Docker CLI","text":"<p>Docker CLI is the primary way that you will interact with Docker. Docker CLI exposes a set of commands that you can provide. The Docker CLI forwards the request to Docker daemon, which then performs the necessary work.</p> <p>While the Docker CLI includes a huge variety of commands and sub-commands, the most common commands that we will work with in this book are as mentioned:</p> bash<pre><code>$ docker build\n$ docker pull\n$ docker run\n$ docker exec\n</code></pre>"},{"location":"books/pocket-devops/#docker-api","title":"Docker API","text":"<p>Docker also provides an API for interacting with the Docker Engine. This is particularly useful if there\u2019s a need to create or manage containers from within applications. </p>"},{"location":"books/pocket-devops/#docker-compose","title":"Docker Compose","text":"<p>Docker Compose is a tool for defining and <code>running multi-container applications</code>. Much like how Docker allows you to build an image for your application and run it in your container, Compose use the same images in combination with a definition file (known as the compose file) to build, launch, and run multi-container applications, including dependent and linked containers.</p> <p>The most common use case for Docker Compose is to run applications and their dependent services (such as databases and caching providers) in the same simple, streamlined manner as running a single container application.</p>"},{"location":"books/pocket-devops/#volume","title":"Volume","text":"<p>Docker volumes are the current recommended method of persisting data stored in containers. Volumes are completely managed by Docker and have many advantages over bind mounts:</p>"},{"location":"books/pocket-devops/#docker-volume-subcommands","title":"Docker Volume Subcommands","text":"<p>Docker exposes the Volume API as a series of subcommands.</p> bash<pre><code>$ docker volume create\n\n$ docker volume inspect\n\n$ docker volume ls\n\n$ docker volume prune\n\n$ docker volume rm\n</code></pre>"},{"location":"books/pocket-devops/#hands-on-docker-commands","title":"Hands on Docker <code>Commands</code>","text":"bash<pre><code># Make sure the docke in installed\n$ docker info\n\n# Working with Docker Images\n# listing of the images available locally\n$ docker image ls\n\n# docker inspect command provides a lot of information about the image\n$ docker image inspect hello-world\n\n# Of importance are the image properties Env, Cmd, and Layers,\n# which tell us about these environment variables.\n\n# Env\n$ docker image inspect hello-world | jq .[].Config.Env\n\n# startup command on the container\n$ docker image inspect hello-world | jq .[].Config.Cmd\n\n# layers associated with the image\n$ docker image inspect hello-world | jq .[].RootFS.Layers\n\n#\n$ docker image inspect nginx | jq .[].Config.ExposedPorts\n</code></pre>"},{"location":"books/tech-books/","title":"Tech Books","text":""},{"location":"books/tech-books/#technology-books","title":"Technology Books","text":""},{"location":"books/tech-books/#self-help-books","title":"Self help books","text":"<p>Make life worthwhile </p>"},{"location":"books/tech-books/#reference","title":"Reference","text":"<ul> <li>Tech Books :github.com</li> <li>E-Books Directory</li> <li>FreeComputerBooks.com</li> </ul>"},{"location":"cryptography/intro/","title":"Intro","text":"<pre><code>Cryptography\n\u2502\n\u251c\u2500\u2500 Symmetric Key Cryptography\n\u2502   \u251c\u2500\u2500 AES\n\u2502   \u251c\u2500\u2500 DES\n\u2502   \u2514\u2500\u2500 3DES\n\u2502\n\u251c\u2500\u2500 Asymmetric Key Cryptography\n\u2502   \u251c\u2500\u2500 RSA\n\u2502   \u251c\u2500\u2500 ECC\n\u2502   \u2514\u2500\u2500 ElGamal\n\u2502\n\u251c\u2500\u2500 Hash Functions\n\u2502   \u251c\u2500\u2500 SHA-256\n\u2502   \u251c\u2500\u2500 MD5\n\u2502   \u2514\u2500\u2500 SHA-3\n\u2502\n\u251c\u2500\u2500 Digital Signatures\n\u2502   \u251c\u2500\u2500 RSA Digital Signatures\n\u2502   \u2514\u2500\u2500 ECDSA\n\u2502\n\u251c\u2500\u2500 Cryptographic Protocols\n\u2502   \u251c\u2500\u2500 TLS/SSL\n\u2502   \u2514\u2500\u2500 IPsec\n\u2502\n\u2514\u2500\u2500 Public Key Infrastructure (PKI)\n    \u251c\u2500\u2500 Certificate Authorities (CAs)\n    \u251c\u2500\u2500 Registration Authorities (RAs)\n    \u2514\u2500\u2500 X.509 Certificates\n</code></pre> Explain to 5 year old, what is Symmetric and Asymmetric Key Cryptography  <p>Alright, let's imagine a simple way to understand symmetric and asymmetric key cryptography using a fun analogy:</p> <p>Symmetric Key Cryptography: The Secret Code</p> <p>Imagine you have a special box that can only be opened with a secret key.</p> <ul> <li>Symmetric Key: You and your friend both have the same secret key to open the box. This key is like a special code that only you two know.</li> <li>How it Works:<ul> <li>Locking the Box: You put a toy inside the box and lock it with the key.</li> <li>Unlocking the Box: Your friend uses the same key to open the box and see the toy inside.</li> </ul> </li> </ul> <p>So, both of you need the same key to lock and unlock the box. If someone else finds the box but doesn\u2019t have the key, they can\u2019t open it.</p> <p>Asymmetric Key Cryptography: The Magic Lock</p> <p>Now, imagine you have a magic lock with two keys \u2013 one to lock and another to unlock.</p> <ul> <li> <p>Asymmetric Keys:</p> <ul> <li>Public Key: This key is like a special lock you can give to everyone. Anyone can use it to lock the box.</li> <li>Private Key: This is the special key you keep secret. Only you can use this key to unlock the box.</li> </ul> </li> <li> <p>How it Works:</p> <ul> <li>Locking the Box: Anyone who has the public key can lock the box, but they can\u2019t open it.</li> <li>Unlocking the Box: Only you, with the private key, can unlock the box and see what\u2019s inside.</li> </ul> </li> </ul> <p>So, people can send you secret things by locking them with the public key, and only you can unlock them with your private key.</p> <p>Summary</p> <ul> <li>Symmetric Key: Same key for locking and unlocking (like a shared secret code).</li> <li>Asymmetric Key: Different keys for locking and unlocking (like a magic lock with one key that everyone can use to lock, and a special key that only you can use to unlock).</li> </ul> <p>This way, both types of keys help keep your secrets safe, but they work in different ways!</p>"},{"location":"cryptography/intro/#reference","title":"Reference","text":"<ul> <li>Cryptography and its Types</li> </ul>"},{"location":"cryptography/steganography/","title":"Steganograpgy","text":"<p>Steganography is the practice of concealing information within other non-secret text or data, such that the presence of the hidden message is not obvious. Unlike encryption, which makes data unreadable to unauthorized users, steganography aims to hide the fact that communication is occurring at all.</p> Key Aspects of Steganography <ol> <li> <p>Purpose: The main goal is to hide information rather than just securing it. This can be useful for covert communication or watermarking.</p> </li> <li> <p>Techniques:</p> <ul> <li>Image Steganography: Hides data within the pixels of an image. For instance, the least significant bits (LSBs) of pixel values can be altered to encode hidden information.</li> <li>Audio Steganography: Conceals data within audio files by manipulating certain audio properties or embedding data in inaudible frequencies.</li> <li>Text Steganography: Involves embedding hidden messages within text by using techniques such as altering word spacing, changing fonts, or using specific letter patterns.</li> <li>Video Steganography: Embeds information in video files, exploiting both spatial and temporal redundancies.</li> <li>Network Steganography: Conceals data within network protocols or traffic patterns.</li> </ul> </li> </ol>"},{"location":"cryptography/steganography/#tools","title":"Tools","text":"ImageAudioVideoTextGeneral-purpose <p><code>Image Steganography Tools</code></p> <p>OpenStego</p> <ul> <li>Features: Provides basic steganography functionality for embedding data in images. Supports PNG and BMP formats.</li> <li>Website: OpenStego</li> </ul> <p>Steghide</p> <ul> <li>Features: A command-line tool that supports embedding data in various file formats, including JPEG, BMP, WAV, and AU.</li> <li>Website: Steghide</li> </ul> <p><code>Audio Steganography Tools</code></p> <p>DeepSound</p> <ul> <li>Features: Allows embedding hidden messages or files within audio files (WAV, MP3, etc.). Includes encryption options.</li> <li>Website: DeepSound</li> </ul> <p>Hide &amp; Seek</p> <ul> <li>Features: Provides a straightforward interface for embedding hidden data in audio files using LSB (Least Significant Bit) encoding.</li> <li>Website: Hide &amp; Seek</li> </ul> <p><code>Video Steganography Tools</code></p> <p>StegoVideo</p> <ul> <li>Features: Enables hiding data within video files by modifying frames or audio tracks. Offers encryption and data management options.</li> <li>Website: StegoVideo</li> </ul> <p>Camouflage</p> <ul> <li>Features: Focuses on hiding data within video files using various techniques and includes built-in encryption.</li> <li>Website: Camouflage</li> </ul> <p><code>Text Steganography Tools</code></p> <p>Covert</p> <ul> <li>Features: A tool for hiding text within other text by using various techniques like text formatting and word spacing.</li> <li>Website: Covert</li> </ul> <p>Text Steganography Tool</p> <ul> <li>Features: Simple tool for embedding text messages into other text files.</li> <li>Website: Text Steganography Tool</li> </ul> <p><code>General-purpose Steganography Tools</code></p> <p>StegExpose</p> <ul> <li>Features: A command-line tool used for detecting steganography in images. Useful for analyzing and identifying hidden data.</li> <li>Website: StegExpose</li> </ul> <p>Xiao Steganography</p> <ul> <li>Features: Supports hiding files in images and offers a user-friendly interface. Also includes options for text steganography.</li> <li>Website: Xiao Steganography</li> </ul>"},{"location":"cryptography/steganography/#online-tools","title":"Online Tools","text":"<p>Steganography Online</p> <ul> <li>Features: Allows users to embed and extract hidden data from images directly through a web interface.</li> <li>Website: Steganography Online</li> </ul> <p>Lsb-Steganography</p> <ul> <li>Features: An online tool for hiding and extracting data from images using LSB encoding.</li> <li>Website: LSB-Steganography</li> </ul> Choosing the Right Tool <p>When selecting a steganography tool, consider the following:</p> <ul> <li>Type of Media: Choose a tool that supports the type of media you are working with (images, audio, video, text).</li> <li>Ease of Use: Some tools are more user-friendly with graphical interfaces, while others may require command-line knowledge.</li> <li>Encryption: For added security, select tools that offer encryption features.</li> <li>Detection and Analysis: Tools for detecting steganography can be useful if you need to identify hidden data within media files.</li> </ul> <p>These tools cater to different needs and levels of expertise, from simple, user-friendly applications to more complex command-line utilities.</p>"},{"location":"database/intro/","title":"Intro","text":"<p>asdad</p>"},{"location":"database/firebase/intro/","title":"Intro","text":"<p>firebase</p>"},{"location":"database/mongodb/intro/","title":"Intro","text":"<p>mongodb</p>"},{"location":"database/mysql/intro/","title":"Intro","text":"<p>mysql</p>"},{"location":"database/postgresql/intro/","title":"Intro","text":"<p>postgresql</p>"},{"location":"database/postgresql/postgress/","title":"Postgresql","text":""},{"location":"database/postgresql/postgress/#solution","title":"Solution","text":"Danger <pre><code>pip install psycopg2\n\nCollecting psycopg2\nDownloading psycopg2-2.9.9.tar.gz (384 kB)\nPreparing metadata (setup.py) ... error\nerror: subprocess-exited-with-error\n\n\u00d7 python setup.py egg_info did not run successfully.\n\u2502 exit code: 1\n\u2570\u2500&gt; [23 lines of output]\n    running egg_info\n</code></pre> <p>It looks like you're having trouble installing <code>psycopg2</code>. This can happen for several reasons. Here are some steps to help you troubleshoot and resolve the issue:</p> <ol> <li> <p>Install Dependencies: <code>psycopg2</code> requires some development packages. Make sure you have the necessary dependencies installed. On Debian-based systems (like Ubuntu), you can run:</p> <pre><code>sudo apt-get install libpq-dev python3-dev\n</code></pre> <p>On Red Hat-based systems (like CentOS), you might need:</p> <pre><code>sudo yum install postgresql-devel python3-devel\n</code></pre> </li> <li> <p>Use the Binary Package: Instead of installing from source, you can try installing the binary version, which doesn't require compilation:</p> <pre><code>pip install psycopg2-binary\n</code></pre> </li> <li> <p>Upgrade <code>pip</code> and <code>setuptools</code>: Sometimes older versions of <code>pip</code> or <code>setuptools</code> can cause installation issues. Upgrade them using:</p> <pre><code>pip install --upgrade pip setuptools\n</code></pre> </li> <li> <p>Check Python Version: Ensure you're using a supported version of Python for the version of <code>psycopg2</code> you're trying to install. Compatibility issues can arise with certain Python versions</p> </li> </ol>"},{"location":"database/postgresql/postgress/#solution-2","title":"Solution 2","text":"Danger <pre><code>python3 manage.py migrate\nOperations to perform:\nApply all migrations: admin, auth, contenttypes, sessions\nRunning migrations:\nTraceback (most recent call last):\nFile \"/home/ninja/.local/share/virtualenvs/api-auth-VbVYN-9u/lib/python3.8/site-packages/django/db/backends/utils.py\", line 87, in _execute\n    return self.cursor.execute(sql)\npsycopg2.errors.InsufficientPrivilege: permission denied for schema public\nLINE 1: CREATE TABLE \"django_migrations\" (\"id\" bigint NOT NULL PRIMA.\n</code></pre> <p>The error you're encountering indicates that the user configured to access your PostgreSQL database does not have sufficient privileges to create tables in the <code>public</code> schema. Here's how you can address this issue:</p> <ol> <li> <p>Check Database User Permissions: Ensure the user specified in your Django settings has the necessary permissions. You can do this by logging into PostgreSQL and checking the user's privileges.</p> <pre><code>\\c your_database_name;  -- Connect to your database\n\\dn+ public;            -- Check the public schema permissions\n</code></pre> </li> <li> <p>Grant Permissions: If the user lacks the required permissions, you can grant them by executing the following SQL commands in your PostgreSQL command line or through a database management tool like pgAdmin:</p> <pre><code>GRANT ALL PRIVILEGES ON SCHEMA public TO your_username;\nGRANT ALL PRIVILEGES ON ALL TABLES IN SCHEMA public TO your_username;\n</code></pre> </li> <li> <p>Update <code>settings.py</code>: Ensure your Django <code>settings.py</code> file has the correct user and database settings. It should look something like this:</p> <pre><code>DATABASES = {\n    'default': {\n        'ENGINE': 'django.db.backends.postgresql',\n        'NAME': 'your_database_name',\n        'USER': 'your_username',\n        'PASSWORD': 'your_password',\n        'HOST': 'localhost',  # or your database host\n        'PORT': '5432',       # default PostgreSQL port\n    }\n}\n</code></pre> </li> <li> <p>Retry Migrations: After adjusting permissions, try running the migrations again:</p> <pre><code>python3 manage.py migrate\n</code></pre> </li> </ol> <p>If you still encounter issues, double-check that you\u2019re connected to the correct database with the correct user, and ensure that the user has not been restricted in other ways (such as connection limits).</p>"},{"location":"database/postgresql/postgress/#postgress-commands","title":"Postgress Commands","text":""},{"location":"database/postgresql/postgress/#what-is-psql","title":"What is psql?","text":"<p><code>psql</code> is the interactive terminal for working with PostgreSQL databases. It allows you to execute SQL commands, manage your databases, and perform administrative tasks. You can run queries, create and modify databases and users, and more.</p> Success <pre><code>CREATE USER ninja_user WITH PASSWORD 'ninja12345';\n\nALTER ROLE ninja_user SET client_encoding TO 'utf8';\n\nALTER ROLE ninja_user SET default_transaction_isolation TO 'read committed';\n\nALTER ROLE ninja_user SET timezone TO 'UTC';\n\nGRANT ALL PRIVILEGES ON DATABASE apiauthdatabase TO ninja_user;\n</code></pre>"},{"location":"database/postgresql/postgress/#method-1using-the-postgresql-shell","title":"Method 1:Using the PostgreSQL Shell","text":"<ol> <li> <p>Open the PostgreSQL Shell: Open your terminal and run:</p> <pre><code>psql -U postgres\n</code></pre> <p>Replace <code>postgres</code> with your username if it's different.</p> </li> <li> <p>List Users: Once in the PostgreSQL shell, execute the following command:</p> <pre><code>\\du\n</code></pre> <p>This command will display a list of all roles (users) along with their attributes.</p> </li> <li> <p>Exit the PostgreSQL Shell: Type <code>\\q</code> to exit.</p> </li> </ol>"},{"location":"database/postgresql/postgress/#method-2-using-sql-query","title":"Method 2: Using SQL Query","text":"<p>You can also retrieve a list of users by executing an SQL query:</p> <pre><code>SELECT usename FROM pg_catalog.pg_user;\n</code></pre> <p>This query will return the names of all users in the PostgreSQL instance.</p>"},{"location":"database/postgresql/postgress/#method-3-using-command-line","title":"Method 3: Using Command Line","text":"<p>If you prefer to list users directly from the command line, you can run:</p> <pre><code>psql -U postgres -c \"\\du\"\n</code></pre> <p>This command will connect to PostgreSQL as the <code>postgres</code> user and execute the <code>\\du</code> command.</p>"},{"location":"database/postgresql/postgress/#commands","title":"Commands","text":"Basic CommandsDatabase <pre><code>-- Open psql shell\npsql -U postgres\nsudo -u postgres psql\n\n-- Create a new database\nCREATE DATABASE mydatabase;\n\n-- List all databases\n\\l\n\n-- Enable Extended Display\n\\x\n\n-- Permissions Check\n\\du\n\n\n-- Exit psql shell\n\\q\n</code></pre> <pre><code>-- Connect to psql\npsql -U postgres\nsudo -u postgres psql\n\n-- Create a new database\nCREATE DATABASE mydatabase;\n\n-- List databases to verify creation\n\\l\n\n-- Delete the database\nDROP DATABASE mydatabase;\n\n-- List databases to verify deletion\n\\l\n\n-- Exit psql\n\\q\n</code></pre> Important Notes <ul> <li>Permissions: Make sure you have the necessary privileges to create and delete databases.</li> <li>Active Connections: You cannot drop a database that has active connections. You may need to disconnect from it first.</li> </ul>"},{"location":"database/postgresql/postgress/#reference","title":"Reference","text":"<ul> <li>How To Use PostgreSQL with your Django Application on Ubuntu 22.04</li> </ul>"},{"location":"docker/intro/","title":"Intro","text":"<p>Docker</p>"},{"location":"docker/react-dockerize-locally/","title":"Dockerize Locally","text":"<p>How to Dockerize a React App and Run it Locally</p>"},{"location":"docker/react-dockerize-locally/#overview","title":"Overview","text":"<p>Creating a Docker image for your React project and running it on your local machine involves several steps. Below is a step-by-step guide to help you containerize your React project using Docker.</p>"},{"location":"docker/react-dockerize-locally/#1-install-docker","title":"1. Install Docker","text":"<p>Before you begin, make sure Docker is installed on your machine. If you haven't installed Docker yet, you can download and install it from Docker's official website.</p>"},{"location":"docker/react-dockerize-locally/#2-prepare-your-react-project","title":"2. Prepare your React project","text":"<p>Assuming you already have a React project, you can follow these steps. If you're starting from scratch, you can create a new React app using Create React App.</p> <pre><code>npx create-react-app my-app\ncd my-app\n</code></pre>"},{"location":"docker/react-dockerize-locally/#3-create-a-dockerfile","title":"3. Create a <code>Dockerfile</code>","text":"<p>The <code>Dockerfile</code> is a text file that contains instructions to build a Docker image for your React application. Create a file named <code>Dockerfile</code> (without any extension) in the root of your React project directory.</p> <p>Here is an example of a <code>Dockerfile</code> for a React app:</p> DockerfileExplanation of the Dockerfile: <pre><code># Step 1: Build the React app\nFROM node:18 AS build\n\n# Set the working directory inside the container\nWORKDIR /app\n\n# Install dependencies\nCOPY package.json package-lock.json ./\nRUN npm install\n\n# Copy the source code to the container\nCOPY . .\n\n# Build the React app\nRUN npm run build\n\n# Step 2: Serve the React app using Nginx\nFROM nginx:alpine\n\n# Copy the build folder from the previous step to Nginx's html directory\nCOPY --from=build /app/build /usr/share/nginx/html\n\n# Expose the port that Nginx is running on\nEXPOSE 80\n\n# Start the Nginx server\nCMD [\"nginx\", \"-g\", \"daemon off;\"]\n</code></pre> <p>Step 1 (Build React app):</p> <ul> <li><code>FROM node:18 AS build</code>: Use the official Node.js image as the base for the build stage.</li> <li><code>WORKDIR /app</code>: Set the working directory inside the container.</li> <li><code>COPY package.json package-lock.json ./</code>: Copy the package files to the container.</li> <li><code>RUN npm install</code>: Install dependencies.</li> <li><code>COPY . .</code>: Copy the rest of the project files to the container.</li> <li><code>RUN npm run build</code>: Build the React app (produces static files in the <code>/build</code> directory).</li> </ul> <p>Step 2 (Serve with Nginx):</p> <ul> <li><code>FROM nginx:alpine</code>: Use the official Nginx image for serving the static files.</li> <li><code>COPY --from=build /app/build /usr/share/nginx/html</code>: Copy the built static files from the previous build stage into the Nginx container.</li> <li><code>EXPOSE 80</code>: Expose port 80 so that you can access the app from your browser.</li> <li><code>CMD [\"nginx\", \"-g\", \"daemon off;\"]</code>: Start the Nginx server when the container runs.</li> </ul>"},{"location":"docker/react-dockerize-locally/#4-create-a-dockerignore-file","title":"4. Create a .dockerignore file","text":"<p>A <code>.dockerignore</code> file tells Docker which files and directories to ignore when building the image. Create a <code>.dockerignore</code> file in your project root and add the following:</p> <pre><code>node_modules\nbuild\n.dockerignore\nDockerfile\n.git\n.gitignore\n</code></pre> <p>This will prevent unnecessary files from being included in the Docker image, keeping it smaller and more efficient.</p>"},{"location":"docker/react-dockerize-locally/#5-build-the-docker-image","title":"5. Build the Docker image","text":"<p>Once your <code>Dockerfile</code> and <code>.dockerignore</code> are set up, you can build the Docker image.</p> <p>Open your terminal in the project root directory and run the following command:</p> <pre><code>docker build -t my-react-app .\n</code></pre> <p>This will build the Docker image and tag it as <code>my-react-app</code>. The <code>.</code> refers to the current directory (where the <code>Dockerfile</code> is located).</p>"},{"location":"docker/react-dockerize-locally/#6-run-the-docker-container","title":"6. Run the Docker container","text":"<p>Once the image is built, you can run it using the following command:</p> <pre><code>docker run -p 3000:80 my-react-app\n</code></pre> <p>This will run the container, mapping port 3000 on your local machine to port 80 on the container (where Nginx is serving your app). You can access the app by navigating to http://localhost:3000 in your web browser.</p>"},{"location":"docker/react-dockerize-locally/#7-access-your-react-app","title":"7. Access your React app","text":"<p>After running the container, you should be able to visit http://localhost:3000 in your browser and see your React app running.</p>"},{"location":"docker/react-dockerize-locally/#8-stop-and-remove-the-container","title":"8. Stop and remove the container","text":"<p>To stop the container, you can use the following command:</p> <pre><code>docker stop &lt;container_id&gt;\n</code></pre> <p>You can get the <code>container_id</code> by running:</p> <pre><code>docker ps\n</code></pre> <p>If you want to remove the container after stopping it, use:</p> <pre><code>docker rm &lt;container_id&gt;\n</code></pre>"},{"location":"docker/react-dockerize-locally/#9-optional-push-to-docker-hub-for-sharing","title":"9. Optional: Push to Docker Hub (for sharing)","text":"<p>If you want to share your Docker image, you can push it to Docker Hub. First, create an account on [Docker Hub].</p> <p>To push your image:</p> <ol> <li> <p>Tag your image with your Docker Hub username:</p> <pre><code>docker tag my-react-app your-dockerhub-username/my-react-app\n</code></pre> </li> <li> <p>Log in to Docker Hub:</p> <pre><code>docker login\n</code></pre> </li> <li> <p>Push the image to Docker Hub:</p> <pre><code>docker push your-dockerhub-username/my-react-app\n</code></pre> </li> </ol> Summary of the process: <ul> <li>Create a <code>Dockerfile</code> for building and serving the React app.</li> <li>Build the image using <code>docker build</code>.</li> <li>Run the image in a container with <code>docker run</code>.</li> <li>Access your React app locally through the mapped port.</li> </ul> <p>This process should work seamlessly for most React apps. If you have specific configurations or requirements (e.g., environment variables), you may need to adjust the <code>Dockerfile</code> accordingly.</p>"},{"location":"linux/debian/","title":"Debian","text":"<p>What is a daemon?</p> <p>A daemon (pronounced <code>DAY-MAN</code>, <code>DAY-MON</code> or sometimes <code>DEE-MON</code>) is a background process that runs on the Linux OS continuously. When we say background, we mean that the program runs without any user interaction. It runs \u201cbehind the scenes\u201c so to speak.</p>"},{"location":"linux/debian/#basic","title":"Basic","text":"<ul> <li> <p>To see which <code>kernel version</code> is running on your system:</p> <p>The command \u201c<code>uname</code>\u201d stands for \u201cUnix name\u201d and tells you about the operating system kernel that\u2019s running.</p> <pre><code># display the operating system kernel that\u2019s running:\n$ uname\n\n# display the kernel version number (the \u201crelease\u201d):\n$ uname -r\n\n# display the machine hardware name:\n$ uname -m\n\n# display all available information:\n$ uname -a\n</code></pre> </li> <li> <p>To Open New Terminal in Ubuntu:</p> <p>Ctrl+Alt+T</p> </li> </ul>"},{"location":"linux/debian/#white-belt","title":"White belt","text":"<ul> <li> <p>To see the hostname:</p> <pre><code>$ hostname\n\n# pwd or Print Working Directory\n$ pwd\n</code></pre> </li> <li> <p>To see your assigned <code>user id</code> and <code>group id</code>, simply issue the <code>id</code> command:</p> <pre><code>$ id\n</code></pre> </li> </ul>"},{"location":"linux/debian/#black-belt","title":"Black Belt","text":"<ul> <li> <p><code>Tmux</code>: Secret Background Windows</p> <p><code>tmux</code> or <code>Terminal Multiplexer</code> is a piece of software used to manage terminal sessions. In addition, it can spin up long-standing terminals in the    background of the Linux operating system that can be saved and recalled later.</p> <p>Tmux cancaome in handy for when you are doing work on a Linux system remotely via SSH and need to keep a session open and to come back to later.</p> bash<pre><code># install\n$ apt-get install tmux\n</code></pre> </li> </ul>"},{"location":"linux/debian/#cat-commands","title":"Cat Commands","text":"<p>Cat means <code>concatenate</code> frequently used command in Linux. It can read data from the file and gives the content as output. It can help us to <code>create</code>, <code>view</code> and <code>concatenate</code> files.</p> <p>So let us see frequently used <code>cat</code> commands.</p> <pre><code># TO VIEW A SINGLE FILE:\n$ cat filename\n\n# TO VIEW MULTIPLE FILES\n$ cat filename1 filename2\n\n# TO VIEW THE CONTENTS OF A FILE PRECEDING WITH LINE NUMBERS:\n$ cat -n filename\n\n# TO CREATE A FILE\n$ cat &gt; new_file\n</code></pre> <p>Ubuntu Important Commands</p> <pre><code># It gives information about how long the system has been running in one line.\n$ uptime\n\n# It displays detailed information about the users who are logged in the system currently.\n$ w\n\n# Using DNS Tools\n# 1. It display information about the domain name, IP address &amp; DNS server\n$ nslookup www.google.com\n\n# 2. It display information about the domain name &amp; IP Addresss\n$ host www.google.com\n\n# 3. dig is a more advanced DNS tool\n$ dig www.google.com\n</code></pre>"},{"location":"linux/debian/#types-of-packages","title":"Types of Packages","text":"<p>The two most popular packages</p> <ol> <li> <p>Debian (<code>.deb</code>) packages:</p> <p>Debian packages are used for distributions like Debian, Ubuntu, and Linux Mint.</p> </li> <li> <p>Red Hat (<code>.rpm</code>):</p> <p>Red Hat packages are used in Fedora, CentOS, RHEL, Suse, and others.</p> </li> </ol>"},{"location":"linux/debian/#package-manager","title":"Package Manager","text":"<ol> <li> <p>Debian package tool (dpkg): DPKG - The True Hero</p> <p><code>Dpkg</code> is a tool that APT is using behind the scenes to install packages. <code>Dpkg</code> doesn\u2019t install dependencies. If we have a <code>.deb</code> package on our system, we can install it easily with dpkg:</p> <pre><code># install\n$ dpkg -i my_package_to_be_installed.deb\n\n# remove\n$ dpkg -r my_package_to_be_removed.deb\n\n# list\n$ dpkg -l\n</code></pre> </li> <li> <p>apt-get</p> <pre><code># syntax\n$ apt-get install &lt;package-name&gt;\n\n$ apt-get install nmap\n</code></pre> </li> <li> <p>Advanced Package Tool (apt)</p> <p><code>apt</code> was introduced to be a bit more user-friendly than <code>apt-get</code>. APT builds on dpkg and adds some special features like managing dependencies, upgrades and searching for package</p> <pre><code># Keeping Software Up to Date\n$ sudo apt update\n</code></pre> </li> <li> <p>Snap (.snap)</p> <p>Snap, a <code>package management system</code> developed by Canonical, Ltd. Unlike <code>apt</code> packages, <code>snap</code> bundles all of the dependencies for a package into a single <code>.snap</code> file.</p> <p>This ensures that the software package is self-contained with its own copy of all of the libraries and assets needed to run. This avoids the potential conflicts of packages relying on different versions of the same shared assets and libraries. The Snap system also allows different versions of the same packages to be installed in parallel.</p> <pre><code># Basic Snap Commands\n\n$ snap list\n$ snap install remmina\n$ snap remove remmina\n$ snap find vlc\n$ snap info remmina\n</code></pre> </li> </ol>"},{"location":"linux/debian/#tar-tape-archive","title":"Tar (Tape Archive)","text":"<p>Tar is a powerful archiving utility used to compress and backup files in the Linux operating system. It is popular tool for creating <code>archives</code> of files and directories.</p> <pre><code># To create a tar archive\n$ tar -cvf archive.tar directory/\n\n# To view the contents of a tar archive\n$ tar -tvf archive.tar\n\n# To extract the contents of a tar archive\n$ tar -xvf archive.tar\n</code></pre> <ul> <li>\u2018<code>c</code>\u2019 flag stands for <code>create</code></li> <li>\u2018<code>x</code>\u2019 flag stands for <code>extract</code></li> <li>\u2018<code>t</code>\u2019 flag stands for <code>list</code></li> <li>\u2018<code>v</code>\u2019 stands for <code>verbose</code></li> <li>\u2018<code>f</code>\u2019 stands for <code>file</code></li> </ul>"},{"location":"linux/debian/#file-permissions-and-ownership","title":"File Permissions and Ownership","text":"<p>In Linux, every file and directory has an owner and a set of permissions that determine who can access and modify the file.</p> <p>File Permissions</p> <p>Each file on a Linux system has <code>three</code> types of permissions:</p> <ul> <li>read <code>r</code>,</li> <li>write <code>w</code>,</li> <li>execute <code>x</code></li> </ul> bash<pre><code>$ ls -l &lt;file-or-folder&gt;\n</code></pre> <p>Changing File Permissions</p> <p>The <code>chmod</code> command is used to change the permissions for a file.</p> bash<pre><code>$ chmod mode &lt;file-or-folder&gt;\n</code></pre> <p>There are two ways to specify the mode:</p> <ul> <li>using a <code>numeric value</code>, or</li> <li>using <code>symbolic values</code>.</li> </ul>"},{"location":"linux/debian/#groups-and-id","title":"Groups and id","text":"<ol> <li> <p>Creating a Group:</p> <p>To create a group, you can use the <code>groupadd</code> command followed by the name of the group you want to create. For example:</p> bash<pre><code>$ sudo groupadd developers\n</code></pre> <p>This creates a new group called <code>developers</code>.</p> </li> <li> <p>Adding <code>Users</code> to a <code>Group</code>:</p> <p>To add users to a group, you can use the <code>usermod</code> command with the <code>-aG</code> option followed by the group name and username. For example:</p> <ul> <li><code>-a</code>, <code>--append</code>:</li> </ul> <p>This option tells <code>usermod</code> to append the user to the supplementary group(s). In other words, it adds the user to the specified group(s) without removing the user from any other groups.</p> <ul> <li><code>-G</code>, <code>--groups</code>:</li> </ul> <p>This option specifies a list of supplementary groups which the user should become a member of. This option sets the list of supplementary groups directly, without appending to the current list of supplementary groups.</p> <p>So, when you use <code>-aG</code> together with usermod, it means you are appending the user to the specified group(s) without removing the user from any other groups, and you're specifying a list of supplementary groups which the user should become a member of.</p> bash<pre><code>$ sudo usermod -aG developers alice\n</code></pre> <p>This adds the user <code>alice</code> to the <code>developers</code> group.</p> </li> <li> <p>Checking Group Membership:</p> <p>To see which <code>groups</code> a <code>user</code> belongs to, you can use the <code>id</code> command followed by the username. For example:</p> bash<pre><code>$ id alice\n</code></pre> </li> </ol>"},{"location":"linux/debian/#to-list-all-groups","title":"To List all groups","text":"<p>To list all the groups in Linux, you can use the <code>getent</code> command followed by the <code>group</code> argument:</p> bash<pre><code>$ getent group\n\n# To check if the \"docker\" group already exists on your system,\n# If the group doesn't exist, this command will not produce any output.\n$ getent group docker\n\n# This command will display all the groups that the user \"bishow\" is a member of.\n$ groups bishow\n</code></pre> <p>Alternatively, you can also view the contents of the <code>/etc/group</code> file, which stores group information. You can use any text editor or commands like <code>cat</code> or <code>less</code> to view its contents:</p> bash<pre><code>$ cat /etc/group\n\n#\n$ grep docker /etc/group\n</code></pre> <p>Notes:</p> <p>Choose whichever method is more convenient for you.</p> <p>Issue Solved:</p> <p>permission denied while trying to connect to the Docker daemon socket at <code>unix:///var/run/docker.sock</code></p> <ol> <li> <p>Check Docker Socket Permissions:</p> <p>Ensure that the Docker socket file (<code>/var/run/docker.sock</code>) has appropriate permissions for the \"docker\" group to read and write to it. You can check and adjust the permissions using the following commands:</p> bash<pre><code>ls -l /var/run/docker.sock\nsudo chmod 666 /var/run/docker.sock\n</code></pre> <p>The first command (<code>ls -l /var/run/docker.sock</code>) shows the current permissions, and the second command (<code>sudo chmod 666 /var/run/docker.sock</code>) grants read and write permissions to all users and groups.</p> </li> <li> <p>Restart Docker Service:</p> <p>Restart the Docker service to apply any changes to group memberships or permissions:</p> bash<pre><code>sudo systemctl restart docker\n</code></pre> </li> <li> <p>Logout and Log Back In:</p> <p>If the above steps don't resolve the issue, try logging out and logging back in to refresh your session and apply any group membership changes:</p> bash<pre><code>logout\n</code></pre> <p>Then log back in and try running <code>docker ps</code> again.</p> </li> </ol> <p>After performing these steps, try running <code>docker ps</code> again without sudo to check if the permission issue has been resolved. If you continue to encounter permission denied errors, further troubleshooting may be needed.</p>"},{"location":"linux/debian/#symlink-linux","title":"Symlink <code>Linux</code>","text":"<p>A symlink (also called a <code>symbolic link</code>) is a type of file in Linux that points to another file or a folder on your computer. Symlinks are similar to shortcuts in Windows.</p> <pre><code># Create a symlink to Director/Folder\n$ ln -s /home/user/Folder &lt;symlink-dir&gt;\n\n# Unlink or Remove a symlink\n$ unlink &lt;path-to-symlink&gt;\n$ rm &lt;path-to-symlink&gt;\n\n# Find and Delete Broken Links\n$ find /home/james -xtype l\n$ find /home/james -xtype l -delete\n\n# Check file/folder is symlink\n$ ls -l &lt;path-to-assumed-symlink&gt;\n\n# SOLVED: sysmlink error\n# 1. Check the File/Folder is sysmlink corrupt or not\n# $ ls -l &lt;file/folder&gt;\n#\n# 2. Unlink the Filer/Folder\n# $ unlink &lt;file/folder&gt;\n#\n# 3. Create a File/Folder\n# $ mkdir Documents\n</code></pre> <p>Reference</p> <ul> <li>How to Create Linux Symlinks</li> <li>Symlink Tutorial in Linux</li> </ul> <p></p> <p>Linux</p> <p>Pass (<code>ubuntu</code>)</p> <p>pass is a very simple password store that keeps passwords inside <code>gpg</code>. It stores, retrieves, generates, and synchronizes passwords securely.</p> bash<pre><code>$ sudo apt update\n$ sudo apt install pass\n</code></pre> <code>service</code> vs <code>systemctl</code> <p>The commands sudo <code>service</code> and <code>systemctl</code> are both used for managing system services in Unix-like operating systems, but they have different purposes and usage patterns.</p> <ol> <li> <p>sudo service:</p> <p><code>sudo service</code> is a command-line tool used for managing services on Unix-like systems, particularly those using SysVinit as the init     system. It provides a simple and consistent interface for starting, stopping, restarting, and querying the status of services.</p> <p>Usage:</p> bash<pre><code># syntax\n$ sudo service &lt;service_name&gt; &lt;action&gt;\n\n#example\n$ sudo systemctl restart apache2\n</code></pre> <p>The service command is often used in older Linux distributions that still use SysVinit as the init system.</p> </li> <li> <p>systemctl:</p> <p><code>systemctl</code> is a command-line tool used for controlling the systemd system and service manager. <code>Systemd</code> is a modern init system used by many     Linux distributions. systemctl allows you to manage services, units, targets, sockets, and more.</p> <p>Usage:</p> bash<pre><code>$ sudo systemctl &lt;action&gt; &lt;service_name&gt;\n$ sudo systemctl restart apache2\n</code></pre> <p><code>systemctl</code> provides more features and capabilities compared to <code>service</code>, and it's the preferred method for managing services on systems that use     systemd.</p> </li> </ol> <p>In summary, if your system is using SysVinit as the init system, you would typically use <code>sudo service</code> to manage services. If your system is using systemd, <code>systemctl</code> is the preferred tool for service management. However, some distributions may provide compatibility layers or aliases to ensure compatibility between the two commands.</p> Creating a <code>User</code> without password <p>Yes, you can add the <code>jenkins</code> user without setting a password. This is often done for system users that don't require interactive login, such as the     <code>jenkins</code> user used for automation tasks.</p> <p>To add the <code>jenkins</code> user without setting a password, you can use the useradd command with the <code>-r</code> (or <code>--system</code>) option, which creates a system user     without a password or home directory. Here's the command:</p> bash<pre><code>sudo useradd -r jenkins\n</code></pre> <p>This command creates the <code>jenkins</code> user as a system user. System users are typically used for services and daemons and do not have passwords or home     directories by default.</p> <p>After adding the user, you can proceed to grant the necessary permissions to the <code>jenkins</code> user, such as adding it to the 'docker' group if needed, to allow it to perform specific tasks without requiring a password.</p> groups &amp; id in unix <p>To see the permissions of a user on a Unix-like system, you can use the <code>groups</code> command or <code>id</code> command.</p> bash<pre><code># Syntax\n$ groups &lt;username&gt;\n$ id &lt;username&gt;\n\n# Example: ($USER refer to the currently logged-in user.)\n$ groups $USER\n</code></pre> Installing Xampp in Linux <pre><code># To Launch XAMPP\nsudo /opt/lampp/./manager-linux-x64.run\n\n# To Unistall\nsudo /opt/lampp/./uninstall\n\n\n# After uninstall, remove the directory\nsudo rm -r /opt/lamp\n</code></pre> <p><code>sudo visudo</code> is a command used in Linux to edit the sudoers file, which determines who has administrative privileges on the system and what commands they can run with elevated permissions using the <code>sudo</code> command. The sudoers file is crucial for system security, as it controls access to sensitive operations.</p> <p>Here's what each part of the command does:</p> <ul> <li> <p><code>sudo</code>:</p> <pre><code>This is a command used in Unix-like operating systems to allow users to run programs with the security privileges of another user (usually the `superuser`, or \"`root`\"). It stands for \"superuser do.\"\n</code></pre> </li> <li> <p><code>visudo</code>:</p> <pre><code>This is a command-line utility specifically designed for editing the ==sudoers file==. It opens the sudoers file in a text editor, but it performs some syntax checking before saving changes to ensure that the file remains in a valid state. This helps prevent accidental misconfigurations that could lock users out of administrative access or potentially compromise system security.\n</code></pre> </li> </ul> <p>In summary, <code>sudo visudo</code> is used to safely edit the sudoers file, which is critical for managing user privileges and access control on a Linux system.</p> <ul> <li>How to Install and Use XAMPP on Ubuntu</li> </ul>"},{"location":"linux/debian/#reference","title":"Reference","text":"<ul> <li>Shell Samurai by Stetson Blake</li> <li>Linux Mastery: 100+ Exercises for Building Your Skills by Frank Anemaet</li> </ul> <p>Blog</p> <ul> <li>Install Docker Engine on Ubuntu 22.04</li> </ul> <p>Icebere Model</p> <ul> <li>a systems thinking model: the iceberg</li> <li>Iceberg Model</li> </ul>"},{"location":"linux/distros/","title":"Distros","text":""},{"location":"linux/distros/#overview","title":"Overview","text":"<p>Linux distributions (distros) are typically categorized based on their package management systems, target users, and specific use cases. Here are the primary categories of Linux distros:</p>"},{"location":"linux/distros/#1-package-management-based-categories","title":"1. Package Management-Based Categories:","text":"<p>Linux distros often differ in the package management systems they use to install, update, and manage software.</p> <p>Debian-based: These distros use <code>.deb</code> packages and the dpkg package management system. The most famous Debian-based distros are:</p> <ul> <li>Ubuntu (and its derivatives like Kubuntu, Xubuntu, etc.)</li> <li>Linux Mint</li> <li>Debian</li> <li>Pop!_OS</li> <li>Elementary OS</li> </ul> <p>Red Hat-based: These distros use <code>.rpm</code> packages and rpm as the package management system. They often come with yum or dnf for package management.</p> <ul> <li>CentOS (CentOS Stream is the successor)</li> <li>Fedora</li> <li>RHEL (Red Hat Enterprise Linux)</li> <li>Rocky Linux</li> <li>AlmaLinux</li> </ul> <p>Arch-based: These distros use a rolling release model and Pacman for package management.</p> <ul> <li>Arch Linux</li> <li>Manjaro</li> <li>EndeavourOS</li> </ul> <p>Slackware-based: Slackware distros are among the oldest, and they rely on simpler package management, usually using <code>.tgz</code> or <code>.txz</code> files.</p> <ul> <li>Slackware</li> <li>Salix OS</li> </ul>"},{"location":"linux/distros/#2-use-case-based-categories","title":"2. Use Case-Based Categories:","text":"<p>Some Linux distros are designed for specific purposes, such as server use, privacy, security, or minimalism.</p> <p>General Purpose: These distros are suitable for most users and serve as general-purpose operating systems.</p> <ul> <li>Ubuntu</li> <li>Fedora</li> <li>Debian</li> <li>Linux Mint</li> </ul> <p>Server-Oriented: Designed for use on servers with a focus on stability, security, and performance.</p> <ul> <li>CentOS / Rocky Linux / AlmaLinux</li> <li>Ubuntu Server</li> <li>Debian Server</li> <li>RHEL</li> </ul> <p>Security/Privacy Focused: These distros focus on security, privacy, or penetration testing.</p> <ul> <li>Kali Linux (penetration testing)</li> <li>Tails (privacy-focused, uses Tor for anonymous browsing)</li> <li>Qubes OS (security-focused, isolation-based architecture)</li> <li>Parrot Security OS</li> </ul> <p>Lightweight or Minimalistic: These distros are designed to be lightweight and suitable for older hardware or users who want full control over their system.</p> <ul> <li>Lubuntu (lightweight Ubuntu variant)</li> <li>Puppy Linux</li> <li>ArchBang (lightweight Arch-based)</li> <li>AntiX</li> </ul> <p>Multimedia Production: These distros are geared towards multimedia content creation like video editing, audio production, and graphic design.</p> <ul> <li>Ubuntu Studio</li> <li>AV Linux</li> <li>Fedora Design Suite</li> </ul>"},{"location":"linux/distros/#3-target-user-based-categories","title":"3. Target User-Based Categories:","text":"<p>Distros can also be classified based on their intended audience, such as beginner, intermediate, or advanced users.</p> <p>Beginner-Friendly: These distros are aimed at users who are new to Linux, with easy-to-use interfaces and simplified package management.</p> <ul> <li>Ubuntu</li> <li>Linux Mint</li> <li>Zorin OS</li> <li>Pop!_OS</li> </ul> <p>Intermediate Users: These distros offer more flexibility and features, but may require more technical knowledge to manage.</p> <ul> <li>Debian</li> <li>Fedora</li> <li>Manjaro</li> </ul> <p>Advanced Users: These distros are for experienced users who prefer to customize and configure their systems.</p> <ul> <li>Arch Linux</li> <li>Gentoo</li> <li>Slackware</li> </ul>"},{"location":"linux/distros/#4-rolling-release-vs-fixed-release","title":"4. Rolling Release vs. Fixed Release:","text":"<p>Rolling Release: These distros continually update and upgrade to the latest software versions. They don\u2019t have major version numbers but instead update continuously.</p> <ul> <li>Arch Linux</li> <li>Manjaro</li> <li>OpenSUSE Tumbleweed</li> </ul> <p>Fixed Release: These distros have specific release cycles with major version numbers, with software updates packaged and tested for each new version.</p> <ul> <li>Ubuntu</li> <li>Fedora</li> <li>Debian</li> </ul>"},{"location":"linux/distros/#5-specialized-categories","title":"5. Specialized Categories:","text":"<p>Some distros cater to niche markets and specific use cases, such as education, gaming, or scientific computing.</p> <p>Education-Focused: These distros are designed for classroom or educational environments.</p> <ul> <li>Edubuntu</li> <li>Sugar on a Stick</li> </ul> <p>Gaming-Focused: These distros focus on optimizing gaming experiences and supporting gaming hardware.</p> <ul> <li>SteamOS</li> <li>Pop!_OS (with a focus on gaming hardware support)</li> </ul>"},{"location":"linux/distros/#conclusion","title":"Conclusion:","text":"<p>Linux distributions can be categorized in various ways, depending on their package management, intended audience, or specific use cases. The most important factor in choosing a distro is understanding your needs and preferences, such as ease of use, security, or hardware compatibility.</p>"},{"location":"linux/intro/","title":"Intro","text":"<p>The word Linux is a bit of a tricky to fully explain. Linux actually refers to the Linux Kernel, which is the core brains of Linux operating systems.</p> <p>Unix vs Linux</p> <p>It\u2019s important to call out that Unix and Linux are not the same. This can be confusing for beginners. Unix was developed in at Bell Labs in the <code>60\u2019s</code>, while Linus Torvalds developed Linux in the <code>90\u2019s</code>, 20-something years later. Much of Linux\u2019s design was inspired by Unix. Linux is even called Unix-like. Linus picked up parts of Unix that he thought were helpful and dropped other pieces. Unix systems are still developed today and running many production systems.</p> <p>Linux Distributions</p> <p>Since Linux is open source, lots of different developers have worked on it and forked their work into separate distributions or \u201cdistros\u201d based on the opinions they have on how the operating system should work. A fork is what happens when software is cloned from other software and takes a different direction. Linux distributions each have their own set of unique features, tools and pre-installed applications.</p> Note <p>It\u2019s important to keep in mind that Linux actually refers to the Linux kernel, while distributions using the kernel are known as Linux operating systems.</p>"},{"location":"linux/intro/#reference","title":"Reference","text":"<ul> <li>CompTIA Linux+ Overview: comptia</li> <li>Best Linux Certification: reddit</li> </ul>"},{"location":"linux/kernel/","title":"Kernel","text":""},{"location":"linux/kernel/#overview","title":"Overview","text":"What is The Kernel? <p>The kernel is the most important part of the Linux operating system. It is the brains and core of the operating system. Linux\u2019s kernel is responsible for starting the OS up, managing processes, memory, devices, processes and so much more.</p> <p>For now, just understand that the Linux Kernel is a crucial piece of the operating system.</p> <p>If you\u2019d like to see which kernel version is running on your system, you can run <code>uname -r</code>:</p> <pre><code>stetson@linux_rocks:~$ uname -r\n5.15.0-56-generic\n</code></pre> <p>There are many kernel versions and because the Linux kernel is open-source, we can inspect the kernel source code, modify it and run it on our own systems.</p> <p>We won\u2019t dive that deep in this course, but know that it\u2019s something you could do. For more info on the Linux kernel, check out Kernel.org</p>"},{"location":"linux/kernel/#kernel-space-vs-user-space","title":"Kernel Space vs User Space","text":"<p>The Linux system is abstracted into 2 distinct layers:</p> <ol> <li>User Mode</li> <li>Kernel Mode.</li> </ol> <p>These are sometimes also called <code>User Space</code> and <code>Kernel Space</code>.</p> <p>When we refer to user space, we\u2019re talking about parts of the operating system dedicated to running user-level programs and applications. This area is separate from kernel-space, which handles running system-level operations that interact directly with the hardware. This separation of concerns keeps Linux modular and secure. If your machine were infected with malware, you wouldn\u2019t want it to have all of the permissions that Kernel mode has. Direct access to hardware, memory and CPU would be a nightmare if it fell into the wrong hands!</p> <ul> <li>User Space and Kernel Space are also sometimes called privilege levels or protection rings.</li> <li>There are 4 \u201crings\u201d where the Kernel, Device Drivers occupy rings 0, 1 and 2.</li> <li>Applications running in User Space run in the least privileged, outter-most layer, ring 3. These keeps Linux secure so that programs can\u2019t directly interact with the innerworkings of the system.</li> </ul> <p>However, we know that some programs definitely interact with our hardware and inner workings of the system. So how do they do it? They use a system call!</p> Note <p>You\u2019ll sometimes also hear <code>user space</code> referred to as <code>userland</code>.</p>"},{"location":"linux/linux-directory-structure/","title":"Linux File Structure","text":"<p>fasdf</p>"},{"location":"linux/ubuntu-logrotation/","title":"Ubuntu LogRotation","text":""},{"location":"linux/ubuntu-logrotation/#overview","title":"Overview","text":""},{"location":"linux/ubuntu-logrotation/#what-is-log-rotation-in-linux","title":"What is Log Rotation in Linux?","text":"<p>Log rotation in Linux is the process of managing log files by renaming or compressing old log files and creating new ones to prevent log files from growing too large and consuming excessive disk space. Over time, log files can become very large, which can lead to performance issues, file system space exhaustion, and difficulties in managing logs.</p> <p>The utility <code>logrotate</code> is commonly used to automate this process on Linux systems. It allows for the rotation, compression, removal, and mailing of log files. Log rotation helps keep logs organized and ensures that your system doesn't run out of space due to excessive log file growth.</p>"},{"location":"linux/ubuntu-logrotation/#default-log-rotation-configuration","title":"Default Log Rotation Configuration","text":"<p>On most Linux systems, log rotation is managed by <code>logrotate</code>. The main configuration file for <code>logrotate</code> is typically found at:</p> <ul> <li><code>/etc/logrotate.conf</code></li> </ul> <p>Additionally, there may be individual configuration files in the <code>/etc/logrotate.d/</code> directory for specific applications.</p>"},{"location":"linux/ubuntu-logrotation/#check-the-default-configuration","title":"Check the Default Configuration","text":"<p>To view the default logrotate configuration, run:</p> <pre><code>cat /etc/logrotate.conf\n</code></pre> <p>Here is an example of a typical <code>/etc/logrotate.conf</code>:</p> <pre><code># Global options\nweekly              # Rotate logs weekly\nrotate 4            # Keep 4 rotated logs (old logs will be deleted after the 4th rotation)\ncreate              # Create new empty logs after rotation\ndateext             # Use date extension for rotated logs (e.g., log-2024-11-18.gz)\ncompress            # Compress rotated logs\ndelaycompress       # Delay compression until the next rotation\nnotifempty          # Do not rotate empty logs\nsharedscripts       # Run post-rotate script only once for all logs\ninclude /etc/logrotate.d/ # Include individual app-specific configurations\n</code></pre>"},{"location":"linux/ubuntu-logrotation/#log-rotation-for-different-use-cases","title":"Log Rotation for Different Use Cases","text":"<ul> <li>System Logs: Typically rotated weekly or monthly, retaining a few weeks or months of logs.</li> <li>Web Server Logs: Often rotated daily due to the high volume of logs generated by web traffic.</li> <li>Application Logs: Depending on the application, rotation frequency can be adjusted based on how much data is generated (e.g., a database might generate logs daily, whereas a low-traffic application might rotate monthly).</li> </ul>"},{"location":"linux/ubuntu-logrotation/#summary","title":"Summary","text":"<p>Log rotation is necessary in Linux to manage log file growth, ensure efficient disk usage, and maintain log integrity. By configuring <code>logrotate</code>, system administrators can automatically rotate, compress, and delete logs, preventing logs from taking up excessive disk space and ensuring system performance remains optimal.</p> Key benefits of log rotation: <ul> <li>Prevents disk space exhaustion.</li> <li>Keeps logs manageable for easier analysis.</li> <li>Improves system performance by preventing large log files from being accessed or written to excessively.</li> <li>Ensures compliance with regulatory requirements regarding log retention.</li> </ul>"},{"location":"linux/ubuntu-logrotation/#question","title":"Question","text":"<p>Why ubunutu log take lot of space issue ?</p> <p>In Ubuntu (or any Linux-based system), large amounts of disk space can sometimes be consumed by log files. This can happen due to a variety of reasons. Below are some of the common causes and how you can address them:</p> <p>1. Log Rotation Issues</p> <p>Ubuntu uses <code>logrotate</code>, a utility that automatically rotates and compresses log files to prevent them from consuming too much space. If log rotation is not configured properly, logs can accumulate and grow indefinitely.</p> Fix: <ul> <li>Check if <code>logrotate</code> is working correctly. You can inspect its configuration at <code>/etc/logrotate.conf</code> and the directory <code>/etc/logrotate.d/</code>.</li> <li>You can manually rotate logs by running:</li> </ul> <p>Rotate logs:</p> <p>If logs have grown too large, you can rotate them manually using <code>logrotate</code>, or you can use <code>truncate</code> to reduce the file size temporarily (but this doesn\u2019t resolve the root cause):</p> <pre><code>sudo truncate -s 0 /var/log/kern.log\nsudo truncate -s 0 /var/log/syslog\n</code></pre> Check for disk and file system issues <p>If <code>kern.log</code> is growing rapidly, it could indicate that there are disk errors or file system issues being logged. Check the health of the disk and file system using tools like smartctl for disk health or fsck for file system checks.</p> smartctl Overview <p><code>smartctl</code> is a command-line utility used to interact with the S.M.A.R.T. (Self-Monitoring, Analysis, and Reporting Technology) system, which is built into most modern hard drives and SSDs. S.M.A.R.T. provides diagnostic and health information about your storage devices, such as error rates, temperature, and wear level, helping to predict drive failures before they occur.</p> <p><code>smartctl</code> is part of the <code>smartmontools</code> package, which is often included by default in many Linux distributions. However, if it's not installed on your system, you can install it manually.</p> <p>How to Install <code>smartmontools</code> on Ubuntu</p> <p>If <code>smartctl</code> is not already installed, you can install it by running the following command:</p> <pre><code>sudo apt update\nsudo apt install smartmontools\n</code></pre> <p>Using <code>smartctl</code></p> <ul> <li> <p>Check the health status of your drive</p> <pre><code>sudo smartctl -H /dev/sda\n</code></pre> </li> </ul> <ul> <li>Log file eating up whole space in Ubuntu 16.04 LTS. Fix?</li> <li>Ubuntu Logs: How to Check and Configure Log Files</li> <li>After deleting log files, Ubuntu server still saying there is no space</li> <li>Ubuntu: large syslog and kern.log files [closed]</li> </ul>"},{"location":"linux/core/file-system-hierarchy/","title":"Linux File System","text":""},{"location":"linux/core/file-system-hierarchy/#linux-directory-structure","title":"Linux Directory Structure","text":"<p>list these directories : <code>ls -l /</code></p>"},{"location":"linux/core/file-system-hierarchy/#types-of-chairs","title":"Types of Chairs","text":"<ol> <li>Conference Chair</li> <li>Executive Chair</li> <li> <p>Ergonomic Chair</p> </li> <li> <p>Best Office Chairs In India \ud83d\udd25 Long Hour Sitting \ud83d\udd25 Best Work From Home Chairs \ud83d\udd25 Ergonomic Chair \ud83d\udd25: Khojdeal</p> </li> </ol>"},{"location":"linux/core/permission-model/","title":"Permission Model","text":"<p>Linux File System</p>"},{"location":"blog/archive/2024/","title":"2024","text":""}]}